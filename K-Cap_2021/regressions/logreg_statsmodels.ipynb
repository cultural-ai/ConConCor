{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b5bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import get_DF, get_indices\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d90d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_DF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e42d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:00<00:00, 114.25it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf = joblib.load(f'vectors/tfidf_0.15.pkl')\n",
    "mat = pd.read_csv(\"vectors/svd_mat_0.15.tsv\", delimiter=\"\\t\", header=None).to_numpy()\n",
    "scaled = StandardScaler(with_mean=False).fit_transform(mat)\n",
    "\n",
    "tfidf_words = tfidf.get_feature_names()\n",
    "mat_inds = get_indices(df.target.unique(), tfidf_words)\n",
    "df[\"mat_ind\"] = df.target.apply(lambda w: mat_inds[w] if w in mat_inds else -1)\n",
    "df = df[df.mat_ind > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1adaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_annotations = {x:list(subdf.y) for x, subdf in df.groupby([\"annotator_x\", \"target\"])}\n",
    "xs, y = list(zip(*target_annotations.items()))\n",
    "x_anno, x_target = list(zip(*xs))\n",
    "\n",
    "mldf = pd.DataFrame([x_anno, x_target, y]).T\n",
    "mldf.columns = [\"x_anno\", \"target\", \"y_ls\"]\n",
    "\n",
    "mldf[\"ratio\"] = mldf.y_ls.apply(lambda ls: sum(ls)/len(ls))\n",
    "mldf = mldf[mldf.ratio != 0.5]\n",
    "mldf[\"maj_vote\"] = mldf.ratio.apply(lambda r: int(r > 0.5))\n",
    "\n",
    "mldf = pd.concat([mldf, pd.get_dummies(mldf[\"x_anno\"])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee3ef2e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e52980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:36<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "pvals = []\n",
    "\n",
    "\n",
    "for _ in tqdm(range(30)):\n",
    "\n",
    "    words_shuffled = np.random.permutation(mldf.target.unique())\n",
    "\n",
    "    ratio = int(mldf.target.unique().shape[0]*0.8)\n",
    "    train_words = set(words_shuffled[:ratio])\n",
    "    msk = mldf.target.isin(train_words)\n",
    "\n",
    "\n",
    "    train_df = mldf[msk]\n",
    "    test_df = mldf[~msk]\n",
    "\n",
    "\n",
    "    target_train, anno_train, Y_train = (np.stack(train_df.target.apply(lambda w: scaled[mat_inds[w]])), \n",
    "                                             train_df.iloc[:, 5:].to_numpy(), \n",
    "                                             train_df.maj_vote.to_numpy())\n",
    "\n",
    "    target_test, anno_test, Y_test = (np.stack(test_df.target.apply(lambda w: scaled[mat_inds[w]])),\n",
    "                                            test_df.iloc[:, 5:].to_numpy(),\n",
    "                                            test_df.maj_vote.to_numpy())\n",
    "\n",
    "    X_train, X_test = np.hstack([target_train, anno_train]), np.hstack([target_test, anno_test])\n",
    "\n",
    "\n",
    "    X = sm.add_constant(X_train)    \n",
    "\n",
    "    results = sm.OLS(Y_train, X).fit()\n",
    "\n",
    "    # results = sm.Probit(Y_train, X).fit()\n",
    "\n",
    "    results.summary()\n",
    "    \n",
    "    pvals.append((results.pvalues[:100] < 0.05).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a54cc6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69.04326342263703, 73.75673657736299)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "st.t.interval(0.95, len(pvals)-1, loc=np.mean(pvals), scale=st.sem(pvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_accs = []\n",
    "accs = []\n",
    "\n",
    "for _ in tqdm(range(5)):\n",
    "    words_shuffled = np.random.permutation(mldf.target.unique())\n",
    "\n",
    "    ratio = int(mldf.target.unique().shape[0]*0.8)\n",
    "    train_words = set(words_shuffled[:ratio])\n",
    "    msk = mldf.target.isin(train_words)\n",
    "\n",
    "    # msk = np.random.rand(len(mldf)) < 0.7\n",
    "\n",
    "    train_df = mldf[msk]\n",
    "    test_df = mldf[~msk]\n",
    "\n",
    "\n",
    "    target_train, anno_train, Y_train = (np.stack(train_df.target.apply(lambda w: scaled[mat_inds[w]])), \n",
    "                                         train_df.iloc[:, 5:].to_numpy(), \n",
    "                                         train_df.maj_vote.to_numpy())\n",
    "\n",
    "    target_test, anno_test, Y_test = (np.stack(test_df.target.apply(lambda w: scaled[mat_inds[w]])),\n",
    "                                        test_df.iloc[:, 5:].to_numpy(),\n",
    "                                        test_df.maj_vote.to_numpy())\n",
    "\n",
    "    X_train, X_test = np.hstack([target_train, anno_train]), np.hstack([target_test, anno_test])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    logreg = LogisticRegression(penalty=\"none\", max_iter=5000, solver=\"lbfgs\")\n",
    "\n",
    "    logreg.fit(X_train, Y_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Logistic Regression\n",
    "\n",
    "    from sklearn.metrics import balanced_accuracy_score, classification_report, accuracy_score,\\\n",
    "                                    confusion_matrix, plot_roc_curve\n",
    "\n",
    "    preds = logreg.predict(X_test)\n",
    "\n",
    "    print(classification_report(Y_test, preds))\n",
    "    b = balanced_accuracy_score(Y_test, preds)\n",
    "    a = accuracy_score(Y_test,\n",
    "                       \n",
    "                       preds)\n",
    "    bal_accs.append(b)\n",
    "    accs.append(a)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(Y_test, preds)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plot_roc_curve(logreg, X_test, Y_test)\n",
    "    _=plt.plot([0,1], [0,1], \"--\", c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c26861a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maj_vote\n",
       "0    6474\n",
       "1    2870\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mldf.groupby(\"maj_vote\").apply(len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
